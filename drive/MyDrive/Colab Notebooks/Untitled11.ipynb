{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPD/Iesrai5jZE3ThMFtgUZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WWl4xwcdCqV8"},"outputs":[],"source":["import numpy as np\n","from keras.datasets import svhn\n","from keras.utils import to_categorical\n","from keras.applications.vgg16 import VGG16\n","from keras.models import Sequential\n","from keras.layers import InputLayer, Dense, Flatten, Dropout\n","from keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","\n","# Load SVHN dataset\n","(x_train, y_train), (x_test, y_test) = svhn.load_data()\n","\n","# Normalize the pixel values between 0 and 1\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","# One-hot encode the labels (SVHN has 10 classes)\n","y_train = to_categorical(y_train, 10)\n","y_test = to_categorical(y_test, 10)\n","\n","# Load VGG16 model pre-trained on ImageNet, without the top layers\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n","\n","# Build the model\n","model = Sequential()\n","\n","# Define input shape for the Sequential model\n","model.add(InputLayer(input_shape=(32, 32, 3)))\n","\n","# Add the VGG16 base model\n","model.add(base_model)\n","\n","# Flatten the output from VGG16's convolutional layers\n","model.add(Flatten())\n","\n","# Add a fully connected layer with 256 units and ReLU activation\n","model.add(Dense(256, activation='relu'))\n","\n","# Add Dropout for regularization\n","model.add(Dropout(0.5))\n","\n","# Add output layer with 10 units (for 10 classes) and softmax activation\n","model.add(Dense(10, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Print the model summary\n","model.summary()\n","\n","# Data augmentation to reduce overfitting\n","datagen = ImageDataGenerator(\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True\n",")\n","\n","# Fit the model using data augmentation\n","batch_size = 64\n","epochs = 3\n","train_generator = datagen.flow(x_train, y_train, batch_size=batch_size)\n","\n","# Train the model\n","history = model.fit(train_generator,\n","                    steps_per_epoch=x_train.shape[0] // batch_size,\n","                    epochs=epochs,\n","                    validation_data=(x_test, y_test))\n","\n","# Plot training & validation accuracy values\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.show()\n","\n","# Evaluate the model on the test data\n","test_loss, test_acc = model.evaluate(x_test, y_test)\n","print(f\"Test accuracy: {test_acc}\")\n"]}]}